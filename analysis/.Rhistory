library(LIEB)
nm = 5
rep(1000.0, nm)
library(LIEB)
ls()
library(LIEB)
data("sim")
ls()
sim
getwd()
load("../output/hyperparameters.Rdata")
ls()
rm(nm)
reduced_classes <- readr::read_tsv("../output/red_class.txt")
reduced_classes <- readr::read_tsv("../output/red_class.txt", col_names = FALSE)
redu
reduced_classes
cgibbs::run_mcmc(sim$data, hyp, 10, reduced_classes)
LIEB::run_mcmc(sim$data, hyp, 10, reduced_classes)
run_mcmc(sim$data, hyp, 10, reduced_classes)
library(LIEB)
data("sim")
load("../output/hyperparameters.Rdata")
reduced_classes <- readr::read_tsv("../output/red_class.txt", col_names = FALSE)
run_mcmc(sim$data, hyp, 10, reduced_classes)
library(LIEB)
data("sim")
load("../output/hyperparameters.Rdata")
reduced_classes <- readr::read_tsv("../output/red_class.txt", col_names = FALSE)
run_mcmc(sim$data, hyp, 10, reduced_classes)
library(workflowr)
?workflowr::wflow_publish
workflowr::wflow_publish(files = *)
workflowr::wflow_publish(files = "*")
workflowr::wflow_publish(files = "*")
workflowr::wflow_publish(files = "*")
warnings()
workflowr::wflow_publish(files = "*", republish = TRUE)
chain <- readRDS("output/chain.rds")
getwd()
chain <- readRDS("../output/chain.rds")
par(mfrow = c(1,4))
# The mean in the first dimension of the third cluster
mu31 <- chain$mu_chains[[3]][,1]
# The variance of the first dimension of the second cluster
sigma21 <- chain$Sigma_chains[[2]][1,1,]
# The covariance between dimensions 2 and 3 in the fourth cluster
sigma423 <- chain$Sigma_chains[[4]][2,3,]
# The mixing weight of the seventh cluster
pi7 <- chain$prop_chain[,7]
plot(mu31, type = "l", xlab = "MCMC iteration", ylab = expression(hat(mu)[31]))
plot(sigma21, type = "l", xlab = "MCMC iteration", ylab = expression(hat(Sigma)[21]))
plot(sigma423, type = "l", xlab = "MCMC iteration", ylab = expression(hat(Sigma)[423]))
plot(pi7, type = "l", xlab = "MCMC iteration", ylab = expression(hat(pi)[7]))
burnin <- 1:200
library(CLIMB)
library(purrr)
par(mfrow = c(1,2))
col_distmat <- compute_distances_between_conditions(chain, burnin)
hc_col <- hclust(as.dist(col_distmat), method = "complete")
plot(hc_col, xlab = "", ylab= "", axes = FALSE, sub = "", main = "Row cluster dendrogram")
row_distmat <- compute_distances_between_clusters(chain, burnin)
row_distmat <- compute_distances_between_clusters(chain, burnin)
hc_row <- hclust(as.dist(row_distmat), method = "complete")
plot(hc_row, xlab = "", ylab= "", axes = FALSE, sub = "", main = "Column cluster dendrogram")
library(ggplot2)
data("sim")
dat <- sim$data
row_reordering <- get_row_reordering(row_clustering = hc_row, chain = chain, burnin = burnin)
molten1 <-
reshape2::melt(data = dplyr::mutate(dat, "row" = row_reordering),
id.vars = "row")
head(molten1)
levels(molten1)
levels(molten1$variable)
levels(molten1$variable) <- paste(1:3)
p1 <- ggplot(data = molten1,
aes(x = variable, y = row, fill = value)) +
geom_raster() +
cowplot::theme_cowplot() +
theme(legend.position = "none", axis.ticks.y = element_blank(), axis.text.y = element_blank()) +
xlab("") + ylab("") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
ggtitle("Bi-clustering\nheatmap") +
scale_fill_gradientn(colours=RColorBrewer::brewer.pal(9,"Greens"))
print(p1)
levels(molten1$variable) <- paste(1:3)[hc_col$order]
?fct_relevel
??fct_relevel
library(forcats)
?fct_relevel
levels(molten1$variable)
forcats::fct_relevel(levels(molten1$variable), molten1$value[hc_col$order])
levels(molten1$variable)
levels(molten1$variable) <- as.factor(paste(1:3))#[hc_col$order]
levels(molten1$variable)
forcats::fct_relevel(levels(molten1$variable), levels = molten1$value[hc_col$order])
forcats::fct_relevel(levels(molten1$variable), ~ .x[hc_col$order])
levels(molten1$variable) <- as.factor(paste(1:3))#[hc_col$order]
levels(molten1$variable) <- forcats::fct_relevel(levels(molten1$variable), ~ .x[hc_col$order])
levels(molten1$variable)
p1 <- ggplot(data = molten1,
aes(x = variable, y = row, fill = value)) +
geom_raster() +
cowplot::theme_cowplot() +
theme(legend.position = "none", axis.ticks.y = element_blank(), axis.text.y = element_blank()) +
xlab("") + ylab("") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
ggtitle("Bi-clustering\nheatmap") +
scale_fill_gradientn(colours=RColorBrewer::brewer.pal(9,"Greens"))
print(p1)
p1 <- ggplot(data = molten1,
aes(x = forcats::fct_relevel(variable, ~ .x[hc_col$order]), y = row, fill = value)) +
geom_raster() +
cowplot::theme_cowplot() +
theme(legend.position = "none", axis.ticks.y = element_blank(), axis.text.y = element_blank()) +
xlab("") + ylab("") +
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
ggtitle("Bi-clustering\nheatmap") +
scale_fill_gradientn(colours=RColorBrewer::brewer.pal(9,"Greens"))
print(p1)
TPMs <- readr::read_tsv("data/tpm_zebrafish.tsv")
TPMs <- readr::read_tsv("../data/tpm_zebrafish.tsv")
# First, find unique conditions (here, there are three)
conditions <- stringr::str_split(names(TPMs)[-(1:2)], pattern = "[[:digit:]]") %>%
purrr::map_chr(1) %>%
unique
library(tidyverse)
rst, find unique conditions (here, there are three)
# First, find unique conditions (here, there are three)
conditions <- stringr::str_split(names(TPMs)[-(1:2)], pattern = "[[:digit:]]") %>%
purrr::map_chr(1) %>%
unique
# Pool together TPMs across replicates
merge_dat <- matrix(NA, nrow = nrow(TPMs), ncol = length(conditions))
for(i in seq_along(conditions)) {
idx <- grepl(pattern = conditions[i], x = names(TPMs))
if(sum(idx) > 1) {
merge_dat[,i] <- rowSums(TPMs[,idx])
} else {
merge_dat[,i] <- TPMs[,idx]
}
}
colnames(merge_dat) <- conditions
# Remove genes which are 0s in all conditions
keep_idx <- apply(merge_dat, 1, function(row) !(all(row == 0)))
genes <- TPMs$gene[keep_idx]
merge_dat <- merge_dat[keep_idx,]
# log2 transform and quantile normalize with limma
l_dat <- log2(merge_dat + 1)
ql_dat <- limma::normalizeQuantiles(l_dat)
# Estimate the central mode
#   It should be the same in every condition, due to quantile normalization
estimated_mode <- modeest::mlv(as.vector(ql_dat), method = "meanshift", par = 5)
# Center the mode over 0
z <- ql_dat - estimated_mode
colnames(z) <- colnames(merge_dat)
# Make a quick histogram of normalized expression from one condition
hist(z[,1], breaks = 30, xlab = "normalized transcripts", main = "Histogram of GFP")
z
plot(z[,1], z[,2])
dim(z)
sc_dat <- readr::read_tsv("../data/olsson2016.tsv")
head(sc_dat)
uid <- sc_dat$uid
sc_dat$uid <- NULL
# Extract cell types
cells <- str_split(colnames(sc_dat), pattern = "\\.") %>%
map_chr(1)
unique(cells)
sc_merge_dat <- matrix(NA, nrow = nrow(sc_dat), ncol = length(unique(cells)))
for(i in seq_along(unique(cells))) {
cell_idx <- cells == unique(cells)[i]
sc_merge_dat[,i] <- rowSums(sc_dat[,cell_idx])
}
colnames(sc_merge_dat) <- unique(cells)
#------------------------------------------------------------------------------
# Do the adjusted quantile normalization
# Remove genes which are 0s in all conditions
keep_idx <- apply(sc_merge_dat, 1, function(X) !all(X == 0))
sc_merge_dat <- sc_merge_dat[keep_idx,]
uid <- uid[keep_idx]
# log2 transform and quantile normalize with limma
l_dat <- log2(sc_merge_dat + 1)
ql_dat <- limma::normalizeQuantiles(l_dat)
dim(ql_dat)
plot(ql_dat[,1], ql_dat[,2])
plot(ql_dat[,1], ql_dat[,3])
range(ql_dat)
ql_dat[ql_dat == 0]
ql_dat[ql_dat == 0] <- rnorm(sum(ql_dat == 0))
plot(ql_dat[,1], ql_dat[,3])
plot(ql_dat[,1], ql_dat[,4])
plot(ql_dat[,1], ql_dat[,4], xlab = "condition 1", ylab = "condition 2")
19,683 * 81
19683 * 81
